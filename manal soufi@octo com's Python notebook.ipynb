{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-venv-soma_env_stage",
      "display_name": "Python (env SOMA_Env_Stage)",
      "language": "python"
    },
    "creator": "manal.soufi@octo.com",
    "createdOn": 1686823384389,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "manal.soufi@octo.com"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Populating the interactive namespace from numpy and matplotlib\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport requests\nimport json"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install requests pandas"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: requests in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (2.27.1)\nRequirement already satisfied: pandas in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages (1.0.5)\nRequirement already satisfied: certifi\u003e\u003d2017.4.17 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from requests) (2023.5.7)\nRequirement already satisfied: idna\u003c4,\u003e\u003d2.5 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from requests) (3.4)\nRequirement already satisfied: charset-normalizer~\u003d2.0.0 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from requests) (2.0.12)\nRequirement already satisfied: urllib3\u003c1.27,\u003e\u003d1.21.1 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from requests) (1.26.15)\nRequirement already satisfied: numpy\u003e\u003d1.13.3 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages (from pandas) (1.19.5)\nRequirement already satisfied: python-dateutil\u003e\u003d2.6.1 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz\u003e\u003d2017.2 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from pandas) (2020.5)\nRequirement already satisfied: six\u003e\u003d1.5 in /home/centos/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib/python3.6/site-packages (from python-dateutil\u003e\u003d2.6.1-\u003epandas) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 14,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example: load a DSS dataset as a Pandas dataframe\n\n#mydataset \u003d dataiku.Dataset(\"mydataset\")\n#mydataset_df \u003d mydataset.get_dataframe()\n\nimport os\n\n# Get the current working directory\ncwd \u003d os.getcwd()\nprint(\"Current working directory:\", cwd)\n\n# Check if the file exists\nfile_path \u003d os.path.join(cwd, \u0027SF_train_prod_prepared.csv\u0027)\nif os.path.exists(file_path):\n    print(\"File found at:\", file_path)\nelse:\n    print(\"File not found.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Current working directory: /home/centos/DATA_DIR/jupyter-run/dku-workdirs/STAGETEST2/manal_soufi_octo_com_s_Python_notebook95273800\nFile not found.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 13,
      "cell_type": "code",
      "metadata": {
        "scrolled": false
      },
      "source": [
        "import requests\nimport json\nimport pandas as pd\n\n# Définir l\u0027URL de l\u0027API service\nurl \u003d \u0027http://35.181.135.32:16000/projects/STAGETEST2/api-designer/defect_detection/endpoints/predict_defect\u0027\n\n# Définir les données CSV d\u0027origine stockées sur Snowflake\ndata_csv \u003d pd.read_csv(\u0027SF_train_prod_prepared.csv\u0027)\n\n# Préparer les données pour la requête POST\nnew_data \u003d data_csv.to_dict(orient\u003d\u0027records\u0027)\n\n# Envoyer la requête POST à l\u0027API service\nresponse \u003d requests.post(url, json\u003dnew_data)\n\n# Vérifier le statut de la réponse\nif response.status_code \u003d\u003d 200:\n    # Récupérer la réponse au format JSON\n    response_json \u003d response.json()\n    \n    # Convertir la réponse en DataFrame pandas\n    new_data_df \u003d pd.DataFrame(response_json)\n    \n    # Charger le dataset existant \"SF_train_mois_prepared\"\n    existing_dataset \u003d dataiku.Dataset(\"SF_train_mois_prepared\")\n    \n    # Ajouter les nouvelles données au dataset existant\n    existing_dataset.write_with_schema(new_data_df, dropAndCreate\u003dTrue)\n    \n    print(\"Les nouvelles données ont été ajoutées avec succès au dataset existant.\")\nelse:\n    print(\"Une erreur s\u0027est produite lors de l\u0027envoi de la requête POST à l\u0027API service.\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] File SF_train_prod_prepared.csv does not exist: \u0027SF_train_prod_prepared.csv\u0027",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-13-97755b597699\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Définir les données CSV d\u0027origine stockées sur Snowflake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 9\u001b[0;31m \u001b[0mdata_csv\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u0027SF_train_prod_prepared.csv\u0027\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Préparer les données pour la requête POST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m\u003d\u003d\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/DATA_DIR/code-envs/python/SOMA_Env_Stage/lib64/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File SF_train_prod_prepared.csv does not exist: \u0027SF_train_prod_prepared.csv\u0027"
          ]
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}